{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES/CONSTANTS\n",
    "\n",
    "# SQLite File Path formatter\n",
    "__SQLITE_0 = \"<PATH_TO_DATABASE_1>.sqlite\"\n",
    "__SQLITE_1 = \"<PATH_TO_DATABASE_2>.sqlite\"\n",
    "__SQLITE_2 = \"<PATH_TO_DATABASE_3>.sqlite\"\n",
    "\n",
    "\n",
    "# sections.shp File Path\n",
    "__SECTION_SHP = \"Data/sections.shp\"\n",
    "\n",
    "# Number of experiments\n",
    "__NUM_EXP = 11\n",
    "\n",
    "# Output File Directory\n",
    "__OUTPUT = \"output/\"\n",
    "\n",
    "# SQL Query to be excecuted for different tables\n",
    "__SQL_EXTRACT_MISECT_QUERY = 'SELECT * FROM MISECT'\n",
    "__SQL_EXTRACT_MILANE_QUERY = 'SELECT * FROM MILANE'\n",
    "__SQL_EXTRACT_MISYS_QUERY = 'SELECT * FROM MISYS'\n",
    "\n",
    "# Columns to extract from different tables\n",
    "__MISECT_COLUMNS = ['ent', 'eid', 'sid', 'flow_capacity', 'speed', 'travel', 'traveltime', 'density', 'flow', 'dtime']\n",
    "__MILANE_COLUMNS = ['ent', 'eid', 'sid', 'lane', 'flow', 'speed', 'density', 'input_flow']\n",
    "__MISYS_COLUMNS = ['ent', 'sid', 'density', 'speed', 'travel', 'traveltime', 'flow', 'dtime', 'qmean']\n",
    "\n",
    "# Actual time for each time step\n",
    "__TIME_REAL = ['14:15', '14:30', '14:45', '15:00', '15:15', '15:30', '15:45', '16:00', '16:15', '16:30', '16:45', '17:00', '17:15', '17:30', '17:45', '18:00', '18:15', '18:30', '18:45', '19:00', '19:15', '19:30', '19:45', '20:00']\n",
    "\n",
    "\n",
    "# Scenario Names\n",
    "__SCENARIOS = [\n",
    "    \"0% Dynamic En-Route\",\n",
    "    \"10% Dynamic En-Route\",\n",
    "    \"20% Dynamic En-Route\",\n",
    "    \"30% Dynamic En-Route\",\n",
    "    \"40% Dynamic En-Route\",\n",
    "    \"50% Dynamic En-Route\",\n",
    "    \"60% Dynamic En-Route\",\n",
    "    \"70% Dynamic En-Route\",\n",
    "    \"80% Dynamic En-Route\",\n",
    "    \"90% Dynamic En-Route\",\n",
    "    \"100% Dynamic En-Route\"\n",
    "]\n",
    "__SCENARIO_PRECENTAGES = [\n",
    "    \"0%\",\n",
    "    \"10%\",\n",
    "    \"20%\",\n",
    "    \"30%\",\n",
    "    \"40%\",\n",
    "    \"50%\",\n",
    "    \"60%\",\n",
    "    \"70%\",\n",
    "    \"80%\",\n",
    "    \"90%\",\n",
    "    \"100%\",\n",
    "]\n",
    "\n",
    "__XTICKS_LABELS_AVG = [\n",
    "    \"Mean Flow (veh/h)\",\n",
    "    \"Mean Density (veh/km/lane)\",\n",
    "    \"Mean Speed (km/h)\",\n",
    "    \"Mean Travel Time (sec/km)\",\n",
    "    \"Mean Delay Time (sec)\",\n",
    "    \"Mean Queue (veh)\"\n",
    "]\n",
    "__XTICKS_LABELS_AVG_SHORT = [\n",
    "    \"Flow \\n(veh/h)\",\n",
    "    \"Density \\n(veh/km/lane)\",\n",
    "    \"Speed \\n(km/h)\",\n",
    "    \"Travel Time \\n(sec/km)\",\n",
    "    \"Delay Time \\n(sec)\",\n",
    "    \"Queue \\n(veh)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQL connection to our SQLite database\n",
    "\n",
    "# A list of established connections to our databases\n",
    "con_0 = []\n",
    "con_1 = []\n",
    "con_2 = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    con_0.append(sqlite3.connect(__SQLITE_0.format(number=i)))\n",
    "    con_1.append(sqlite3.connect(__SQLITE_1.format(number=i)))\n",
    "    con_2.append(sqlite3.connect(__SQLITE_2.format(number=i)))\n",
    "\n",
    "# Run SQL query and convert SQL to DataFrame\n",
    "\n",
    "# List of dataframes extracted from each experiment\n",
    "df_0_misys = []\n",
    "df_1_misys = []\n",
    "df_2_misys = []\n",
    "for i in range(__NUM_EXP):\n",
    "    # Run SQL\n",
    "    query_0 = pd.read_sql(__SQL_EXTRACT_MISYS_QUERY, con_0[i])\n",
    "    query_1 = pd.read_sql(__SQL_EXTRACT_MISYS_QUERY, con_1[i])\n",
    "    query_2 = pd.read_sql(__SQL_EXTRACT_MISYS_QUERY, con_2[i])\n",
    "    \n",
    "    # Convert SQL to DataFrame\n",
    "    df_0 = pd.DataFrame(query_0, columns = __MISYS_COLUMNS)\n",
    "    df_0_misys.append(df_0)\n",
    "    df_1 = pd.DataFrame(query_1, columns = __MISYS_COLUMNS)\n",
    "    df_1_misys.append(df_1)\n",
    "    df_2 = pd.DataFrame(query_2, columns = __MISYS_COLUMNS)\n",
    "    df_2_misys.append(df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sections.shp shapefile\n",
    "sections = gpd.read_file(__SECTION_SHP)\n",
    "sections.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_rep = sections[sections['eid'] == str(243)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sections_rep.plot(figsize=(15, 15))\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.title('Road Sections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_temp = sections.pivot_table(index=['eid'], aggfunc='size')\n",
    "sections_temp[sections_temp > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_results(df_list: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a list of pd.DataFrame, compute the average of the specified columns\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    df_list: list\n",
    "        A list of pd.DataFrame\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    processed_df: pd.DataFrame\n",
    "        A pd.DataFrame containing the average of the specified columns\n",
    "    \"\"\"\n",
    "    processed_dfs = []\n",
    "    for df in df_list:\n",
    "        # Compute the mean of the specified columns\n",
    "        mean_df = df[['flow', 'density', 'speed', 'traveltime', 'dtime', 'qmean']].mean()\n",
    "        processed_dfs.append(mean_df)\n",
    "    # Concatenate the series into a DataFrame\n",
    "    processed_df = pd.concat(processed_dfs, axis=1).T\n",
    "    processed_df.insert(0, \"Scenario\", __SCENARIOS)\n",
    "    # processed_df.set_index(\"Scenario\", inplace=True)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_misys_avg = compute_average_results(df_0_misys)\n",
    "df_0_misys_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_misys_avg = compute_average_results(df_1_misys)\n",
    "df_1_misys_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_misys_avg = compute_average_results(df_2_misys)\n",
    "df_2_misys_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Scenario\" column from each DataFrame\n",
    "df_0_misys_avg_numeric = df_0_misys_avg.drop(\"Scenario\", axis=1)\n",
    "df_1_misys_avg_numeric = df_1_misys_avg.drop(\"Scenario\", axis=1)\n",
    "df_2_misys_avg_numeric = df_2_misys_avg.drop(\"Scenario\", axis=1)\n",
    "\n",
    "# Concatenate the DataFrames along the column axis\n",
    "concatenated_df_misys_all = pd.concat([df_0_misys_avg_numeric, df_1_misys_avg_numeric, df_2_misys_avg_numeric], axis=1)\n",
    "# concatenated_df_misys_all = pd.concat([df_0_misys_avg, df_1_misys_avg, df_2_misys_avg], axis=1)\n",
    "\n",
    "# Compute the mean along the row axis\n",
    "mean_df = concatenated_df_misys_all.groupby(concatenated_df_misys_all.columns, axis=1).mean()\n",
    "mean_df = mean_df.round(4)\n",
    "mean_df = mean_df[['flow', 'density', 'speed', 'traveltime', 'dtime', 'qmean']]\n",
    "\n",
    "# Add the \"Scenario\" column back\n",
    "mean_df.insert(0, \"Scenario\", __SCENARIOS)\n",
    "# mean_df.set_index(\"Scenario\", inplace=True)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.to_csv(__OUTPUT + \"misys_avg_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for the \"better\" rule\n",
    "better_rule = {'flow': 'higher', 'speed': 'higher', 'density': 'lower', 'traveltime': 'lower', 'dtime': 'lower', 'qmean': 'lower'}\n",
    "\n",
    "# Standardize the columns according to the \"better\" rule\n",
    "mean_df_standardized = mean_df.copy()\n",
    "for col in better_rule.keys():\n",
    "    if better_rule[col] == 'higher':\n",
    "        # For \"higher is better\", we standardize by subtracting the min and dividing by the range\n",
    "        mean_df_standardized[col] = (mean_df[col] - mean_df[col].min()) / (mean_df[col].max() - mean_df[col].min())\n",
    "    else:\n",
    "        # For \"lower is better\", we standardize by subtracting the value from max and dividing by the range\n",
    "        mean_df_standardized[col] = (mean_df[col].max() - mean_df[col]) / (mean_df[col].max() - mean_df[col].min())\n",
    "\n",
    "# Drop the \"Scenario\" column for the heatmap\n",
    "mean_df_standardized_numeric = mean_df_standardized.drop(\"Scenario\", axis=1)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "htmp = sns.heatmap(\n",
    "    mean_df_standardized_numeric, \n",
    "    annot=mean_df.drop(\"Scenario\", axis=1).values, \n",
    "    xticklabels=__XTICKS_LABELS_AVG_SHORT, \n",
    "    yticklabels=__SCENARIO_PRECENTAGES, fmt='.2f', \n",
    "    cmap='RdYlGn', \n",
    "    linewidths=0.5,\n",
    "    \n",
    ")\n",
    "htmp.set(ylabel=\"Dynamic En-Route\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Heatmap of Average Metrics for All Scenarios')\n",
    "plt.savefig(__OUTPUT + \"misys_avg_all_heatmap_short.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
