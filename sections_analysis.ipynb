{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e814362c",
   "metadata": {},
   "source": [
    "# Fremont Traffic Congestion Analysis (Navigation App Usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e054f41",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "TODO: Clean up the notebook\n",
    "- [Imports](#imports)\n",
    "- [Global Functions](#global-functions)\n",
    "- [Data Preprocessing](#data-preprocessing)\n",
    "- [Section Plots](#section-plots)\n",
    "- [Data Copying](#data-copying)\n",
    "- [Percentage of Congested Links](#percentage-of-congested-links)\n",
    "- [Percentage of Congested Links by Road Type](#percentage-of-congested-links-by-road-type)\n",
    "- [Visualize the congested Area on the Map at Different SRC](#visualize-the-congested-area-on-the-map-at-different-src)\n",
    "- [Macroscopic Fundamental Diagram](#macroscopic-fundamental-diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990524ff",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4198ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7990e4",
   "metadata": {},
   "source": [
    "# Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc79b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_experiment(gdf_list, col_name):\n",
    "    \"\"\"\n",
    "    Plot all the curves of the data for a list of GeoDataFrames on the designated column.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    gdf_list --- a list of GeoDataFrame that contains the processed data \n",
    "                 merged from sections.shp and sqlite output from aimsun\n",
    "    col_name --- the name of the column to be plotted\n",
    "    \"\"\" \n",
    "    for i in range(len(gdf_list)):\n",
    "        plt.plot(np.array(gdf_list[i][col_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09abb17",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e9ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES/CONSTANTS\n",
    "\n",
    "# SQLite File Path formatter\n",
    "__SQLITE_PATH_FORMAT = \"<PATH_TO_DATABASE>.sqlite\"\n",
    "\n",
    "# sections.shp File Path\n",
    "__SECTION_SHP = \"<PATH_TO_SECTIONS_FILE>.shp\"\n",
    "\n",
    "# Number of experiments\n",
    "__NUM_EXP = 11\n",
    "\n",
    "# Output File Directory\n",
    "__OUTPUT = \"output/\"\n",
    "\n",
    "# SQL Query to be excecuted for different tables\n",
    "__SQL_EXTRACT_MISECT_QUERY = 'SELECT * FROM MISECT'\n",
    "__SQL_EXTRACT_MILANE_QUERY = 'SELECT * FROM MILANE'\n",
    "\n",
    "# Columns to extract from different tables\n",
    "__MISECT_COLUMNS = ['ent', 'eid', 'sid', 'flow_capacity', 'speed', 'travel', 'traveltime', 'density', 'flow', 'dtime']\n",
    "__MILANE_COLUMNS = ['ent', 'eid', 'sid', 'lane', 'flow', 'speed', 'density', 'input_flow']\n",
    "\n",
    "# Actual time for each time step\n",
    "__TIME_REAL = ['14:15', '14:30', '14:45', '15:00', '15:15', '15:30', '15:45', '16:00', '16:15', '16:30', '16:45', '17:00', '17:15', '17:30', '17:45', '18:00', '18:15', '18:30', '18:45', '19:00', '19:15', '19:30', '19:45', '20:00']\n",
    "\n",
    "# Threshold for a section to be considered congested\n",
    "rho = np.linspace(0.1, 0.9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a46110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a SQL connection to our SQLite database\n",
    "\n",
    "# A list of established connections to our databases\n",
    "con = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    con.append(sqlite3.connect(__SQLITE_PATH_FORMAT.format(number=i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c48d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run SQL query and convert SQL to DataFrame\n",
    "\n",
    "# List of dataframes extracted from each experiment\n",
    "df = []\n",
    "df_milane = []\n",
    "for i in range(__NUM_EXP):\n",
    "    # Run SQL\n",
    "    query = pd.read_sql(__SQL_EXTRACT_MISECT_QUERY, con[i])\n",
    "    \n",
    "    # Convert SQL to DataFrame\n",
    "    dataframe = pd.DataFrame(query, columns = __MISECT_COLUMNS)\n",
    "    df.append(dataframe)\n",
    "    \n",
    "    query = pd.read_sql(__SQL_EXTRACT_MILANE_QUERY, con[i])\n",
    "    dataframe = pd.DataFrame(query, columns = __MILANE_COLUMNS)\n",
    "    df_milane.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf738e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the sections.shp shapefile\n",
    "sections = gpd.read_file(__SECTION_SHP)\n",
    "sections.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6a18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a deep copy of df as back up in order not to rerun the above cell\n",
    "df_copy = copy.deepcopy(df)\n",
    "df_milane_copy = copy.deepcopy(df_milane)\n",
    "sections_copy = copy.deepcopy(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e5ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4655a51",
   "metadata": {},
   "source": [
    "# Section Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc0d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections_ppp = sections[sections['name']=='Paseo Padre Parkway']\n",
    "sections_ppp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1194e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections_mission = sections[sections['name']=='Mission Boulevard']\n",
    "sections_mission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899b36e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sections_i680 = sections[sections['func_class']==1]\n",
    "sections_i680 = sections_i680[sections_i680['name']!='Mission Boulevard']\n",
    "sections_i680.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58776dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sections.plot(figsize=(15, 15))\n",
    "# Position and layout\n",
    "scale_bar = ScaleBar(\n",
    "    dx=1,\n",
    "    location='upper left',  # in relation to the whole plot\n",
    "    label_loc='left', scale_loc='bottom'  # in relation to the line\n",
    ")\n",
    "ax.add_artist(scale_bar)\n",
    "x, y, arrow_length = 0.05, 0.95, 0.07\n",
    "ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "            arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "            ha='center', va='center', fontsize=20,\n",
    "            xycoords=ax.transAxes)\n",
    "ax.xaxis.set_tick_params(labelbottom=False)\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.title('Road Sections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715aec12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sections_i680.plot(figsize=(15, 15))\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.title('I-680')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af1c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sections_mission.plot(figsize=(15, 15))\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.title('Mission Boulevard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14acc225",
   "metadata": {},
   "source": [
    "# Data Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059a8c0-5e06-4f6a-803d-0fe05081596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece6215-c9e9-439d-907b-cf22e5901e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the sections with missing average speed\n",
    "df_total = []\n",
    "df_local = []\n",
    "df_throu = []\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] >= 0.0]\n",
    "    df_total.append(copy.deepcopy(df[i][df[i]['sid'] == 0]))\n",
    "    df_local.append(copy.deepcopy(df[i][df[i]['sid'] == 1]))\n",
    "    df_throu.append(copy.deepcopy(df[i][df[i]['sid'] == 2]))\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_throu[i].shape for i in range(__NUM_EXP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6813a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess dataframe to merge with sections\n",
    "\n",
    "group_cols = ['ent','eid']\n",
    "# identify the columns which we want to average; this could\n",
    "# equivalently be defined as list(df.columns[4:])\n",
    "metric_cols = ['flow_capacity']\n",
    "\n",
    "# create a new DataFrame with a MultiIndex consisting of the group_cols\n",
    "# and a column for the mean of each column in metric_cols\n",
    "aggs = []\n",
    "for i in range(__NUM_EXP):\n",
    "    aggs.append(df_total[i].groupby(group_cols)[metric_cols].mean())\n",
    "\n",
    "# 1. remove the metric_cols from df because we are going to replace them\n",
    "# with the means in aggs \n",
    "# 2. dedupe to leave only one row with each combination of group_cols\n",
    "# in df\n",
    "for i in range(__NUM_EXP):\n",
    "    # Step 1\n",
    "    df_total[i].drop(metric_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Step 2\n",
    "    # df[i].drop_duplicates(subset=group_cols, keep='last', inplace=True)\n",
    "\n",
    "# add the mean columns from aggs into df\n",
    "for i in range(__NUM_EXP):\n",
    "    df_total[i] = df_total[i].merge(right=aggs[i], right_index=True, left_on=group_cols, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea513547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge datasets: sections and dataframe\n",
    "sections_m = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    sections_m.append(pd.merge(df_total[i], sections, how='left', left_on='eid', right_on='eid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the merged sections into GeoDataFrame and replace null values with 0\n",
    "gdf = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf.append(gpd.GeoDataFrame(sections_m[i], geometry='geometry'))\n",
    "    gdf[i]['flow_capacity'] = gdf[i]['flow_capacity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef74e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group each GeoDataFrame on timestep and aggregate by mean\n",
    "# Remove the first row as it is the average of the rest\n",
    "gdf_agg = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_agg.append(gdf[i].groupby('ent').agg(np.mean).iloc[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da18c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plot_experiment(gdf_agg, 'flow_capacity')\n",
    "plt.legend([\"0% SRC(All SUE)\",\n",
    "                     \"10% SRC\",\n",
    "                     \"20% SRC\",\n",
    "                     \"30% SRC\",\n",
    "                     \"40% SRC\",\n",
    "                     \"50% SRC\",\n",
    "                     \"60% SRC\",\n",
    "                     \"70% SRC\",\n",
    "                     \"80% SRC\",\n",
    "                     \"90% SRC\",\n",
    "                     \"100% All SRC (No SUE)\"])\n",
    "default_x_ticks = range(len(__TIME_REAL))\n",
    "plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "plt.yticks(fontsize='15')\n",
    "plt.title('Mean Flow-Capacity Ratio')\n",
    "plt.savefig(__OUTPUT + 'Mean Flow-Capacity Ratio.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f48a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the data of I-680 from GeoDataframe, aggregate(mean) them, and plot them\n",
    "# similar to the above process\n",
    "gdf_i680 = []\n",
    "gdf_i680_agg = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_i680.append(gdf[i][(gdf[i]['func_class'] == 1) & (gdf[i]['name'] != \"Mission Boulevard\")])\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_i680_agg.append(gdf_i680[i].groupby('ent').agg(np.mean).iloc[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9826c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment on I-680\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plot_experiment(gdf_i680_agg, 'flow_capacity')\n",
    "plt.legend([\"0% SRC(All SUE)\",\n",
    "                     \"10% SRC\",\n",
    "                     \"20% SRC\",\n",
    "                     \"30% SRC\",\n",
    "                     \"40% SRC\",\n",
    "                     \"50% SRC\",\n",
    "                     \"60% SRC\",\n",
    "                     \"70% SRC\",\n",
    "                     \"80% SRC\",\n",
    "                     \"90% SRC\",\n",
    "                     \"100% All SRC (No SUE)\"])\n",
    "plt.title('I-680 Volume-to-Capacity Ratio')\n",
    "default_x_ticks = range(len(__TIME_REAL))\n",
    "plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "plt.yticks(fontsize='15')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcb087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the data of I-680 from GeoDataframe, aggregate(mean) them, and plot them\n",
    "# similar to the above process\n",
    "gdf_mission = []\n",
    "gdf_mission_agg = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_mission.append(gdf[i][gdf[i]['name'] == \"Mission Boulevard\"])\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_mission_agg.append(gdf_mission[i].groupby('ent').agg(np.mean).iloc[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71704c1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment on Mission Boulevard\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plot_experiment(gdf_mission_agg, 'flow_capacity')\n",
    "plt.legend([\"0% SRC(All SUE)\",\n",
    "                     \"10% SRC\",\n",
    "                     \"20% SRC\",\n",
    "                     \"30% SRC\",\n",
    "                     \"40% SRC\",\n",
    "                     \"50% SRC\",\n",
    "                     \"60% SRC\",\n",
    "                     \"70% SRC\",\n",
    "                     \"80% SRC\",\n",
    "                     \"90% SRC\",\n",
    "                     \"100% All SRC (No SUE)\"])\n",
    "plt.title('Mission Boulevard Volume-to-Capacity Ratio')\n",
    "default_x_ticks = range(len(__TIME_REAL))\n",
    "plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "plt.yticks(fontsize='15')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fb5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the data of Paseo Padre Parkway from GeoDataframe, aggregate(mean) them, and plot them\n",
    "# similar to the above process\n",
    "gdf_ppp = []\n",
    "gdf_ppp_agg = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_ppp.append(gdf[i][gdf[i]['name'] == \"Paseo Padre Parkway\"])\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_ppp_agg.append(gdf_ppp[i].groupby('ent').agg(np.mean).iloc[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a055693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment on Paseo Padre Parkway\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plot_experiment(gdf_mission_agg, 'flow_capacity')\n",
    "plt.legend([\"0% SRC(All SUE)\",\n",
    "                     \"10% SRC\",\n",
    "                     \"20% SRC\",\n",
    "                     \"30% SRC\",\n",
    "                     \"40% SRC\",\n",
    "                     \"50% SRC\",\n",
    "                     \"60% SRC\",\n",
    "                     \"70% SRC\",\n",
    "                     \"80% SRC\",\n",
    "                     \"90% SRC\",\n",
    "                     \"100% All SRC (No SUE)\"])\n",
    "default_x_ticks = range(len(__TIME_REAL))\n",
    "plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "plt.yticks(fontsize='15')\n",
    "plt.title('Paseo Padre Parkway Volume-to-Capacity Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baeedf6",
   "metadata": {},
   "source": [
    "# Percentage of Congested Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe5cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5221bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_length = sections['geometry'].length.sum()\n",
    "total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332291ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the sections with missing average speed\n",
    "df_total = []\n",
    "df_local = []\n",
    "df_throu = []\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] >= 0.0]\n",
    "    df_total.append(copy.deepcopy(df[i][df[i]['sid'] == 0]))\n",
    "    df_local.append(copy.deepcopy(df[i][df[i]['sid'] == 1]))\n",
    "    df_throu.append(copy.deepcopy(df[i][df[i]['sid'] == 2]))\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_throu[i].shape for i in range(__NUM_EXP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba7c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess dataframe to merge with sections\n",
    "\n",
    "group_cols = ['ent', 'eid']\n",
    "# identify the columns which we want to average; this could\n",
    "# equivalently be defined as list(df.columns[4:])\n",
    "metric_cols = ['speed']\n",
    "\n",
    "# create a new DataFrame with a MultiIndex consisting of the group_cols\n",
    "# and a column for the mean of each column in metric_cols\n",
    "aggs = []\n",
    "for i in range(__NUM_EXP):\n",
    "    aggs.append(df_total[i].groupby(group_cols)[metric_cols].mean())\n",
    "\n",
    "# 1. remove the metric_cols from df because we are going to replace them\n",
    "# with the means in aggs \n",
    "# 2. dedupe to leave only one row with each combination of group_cols\n",
    "# in df\n",
    "for i in range(__NUM_EXP):\n",
    "    # Step 1\n",
    "    df_total[i].drop(metric_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Step 2\n",
    "    # df[i].drop_duplicates(subset=group_cols, keep='last', inplace=True) # No dedupe for congestion\n",
    "\n",
    "# add the mean columns from aggs into df\n",
    "for i in range(__NUM_EXP):\n",
    "    df_total[i] = df_total[i].merge(right=aggs[i], right_index=True, left_on=group_cols, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66628839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge datasets: sections and dataframe\n",
    "sections_cong = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    sections_cong.append(pd.merge(df_total[i], sections, how='left', left_on='eid', right_on='eid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e467d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(__NUM_EXP):\n",
    "    sections_cong[i] = sections_cong[i][['ent', 'eid', 'speed', 'speed_limit', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee47d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the merged sections into GeoDataFrame and drop null values\n",
    "gdf = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf.append(gpd.GeoDataFrame(sections_cong[i], geometry='geometry'))\n",
    "    gdf[i]['speed'] = gdf[i]['speed'].dropna()\n",
    "    gdf[i]['length'] = gdf[i]['geometry'].length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19b3c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column for each section at each threshold,\n",
    "# congested = 1, else 0\n",
    "# Threshold for a section to be considered congested\n",
    "rho = np.linspace(0.1, 0.9, 9)\n",
    "for threshold in rho:\n",
    "    for i in range(__NUM_EXP):\n",
    "        speed_ratio = gdf[i]['speed'] / gdf[i]['speed_limit']\n",
    "        gdf[i]['congested at rho = ' + str(round(threshold, 1))] = [int(r < threshold) for r in speed_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267dfee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next steps: multiply the congested at rho column \n",
    "# with section length to create a congestion weight column\n",
    "# that can be summed to get our desired result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2ac14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column for congestion weight at each threshold,\n",
    "# congested = 1, else 0\n",
    "for threshold in rho:\n",
    "    for i in range(__NUM_EXP):\n",
    "        weight = gdf[i]['length'] * gdf[i]['congested at rho = ' + str(round(threshold, 1))]\n",
    "        gdf[i]['weight at rho = ' + str(round(threshold, 1))] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627fb8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group each GeoDataFrame on timestep and aggregate by sum\n",
    "# Remove the first row as it is the average of the rest\n",
    "gdf_agg = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    gdf_agg.append(gdf[i].groupby('ent').agg(np.sum).iloc[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf8035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for threshold in rho:\n",
    "    for i in range(__NUM_EXP):\n",
    "        gdf_agg[i]['congestion ratio at rho = ' + str(round(threshold, 1))] = gdf_agg[i]['weight at rho = ' + str(round(threshold, 1))] / total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f09d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(gdf_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c570a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment on Mission Boulevard\n",
    "for threshold in rho:\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_experiment(gdf_agg, 'congestion ratio at rho = ' + str(round(threshold, 1)))\n",
    "\n",
    "    plt.legend([\"0% SRC(All SUE)\",\n",
    "                         \"10% SRC\",\n",
    "                         \"20% SRC\",\n",
    "                         \"30% SRC\",\n",
    "                         \"40% SRC\",\n",
    "                         \"50% SRC\",\n",
    "                         \"60% SRC\",\n",
    "                         \"70% SRC\",\n",
    "                         \"80% SRC\",\n",
    "                         \"90% SRC\",\n",
    "                         \"100% All SRC (No SUE)\"])\n",
    "    title = 'Weighted Congestion Ratio over Time Step (Threshold = {threshold})'.format(threshold=str(round(threshold, 1)))\n",
    "    plt.title(title)\n",
    "    default_x_ticks = range(len(__TIME_REAL))\n",
    "    plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "    plt.yticks(fontsize='15')\n",
    "    plt.savefig(__OUTPUT + f'{title}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17405c5c-1f8c-40ac-a4d9-98fd814cb918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_congested_links(gdf, sections, rho):\n",
    "    congested = copy.deepcopy(gdf)\n",
    "    sections = copy.deepcopy(sections)\n",
    "    sections_congested = []\n",
    "    \n",
    "    # Filter out the congested sections\n",
    "    for i in range(__NUM_EXP):\n",
    "        congested[i] = congested[i][congested[i]['congested at rho = {number}'.format(number=rho)] == 1]\n",
    "        congested[i] = congested[i][['ent', 'eid', 'congested at rho = {number}'.format(number=rho)]]\n",
    "        \n",
    "    # Map the congested sections to the sections.shp\n",
    "    for i in range(__NUM_EXP):\n",
    "        sections_congested.append(sections[sections['eid'].isin(congested[i]['eid'])])\n",
    "        \n",
    "    # Plot\n",
    "    for i in range(__NUM_EXP): # Experiment with smaller range\n",
    "        ax = sections_congested[i].plot(figsize=(15, 15), color='red')\n",
    "        print(sections_congested[i].crs)\n",
    "        # cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "        plt.xlim([591900, 597200])\n",
    "        plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "        # plt.xticks(fontsize=24, rotation=45)\n",
    "        # plt.yticks(fontsize=24)\n",
    "        scale_bar = ScaleBar(\n",
    "            dx=1,\n",
    "            location='upper left',  # in relation to the whole plot\n",
    "            label_loc='left', scale_loc='bottom'  # in relation to the line\n",
    "        )\n",
    "        ax.add_artist(scale_bar)\n",
    "        x, y, arrow_length = 0.05, 0.95, 0.07\n",
    "        ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "                    arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "                    ha='center', va='center', fontsize=20,\n",
    "                    xycoords=ax.transAxes)\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "        ax.yaxis.set_tick_params(labelleft=False)\n",
    "        # plt.title('Congestion Points when rho = {number} where SRC = {percent}%'.format(number=rho, percent=i*10))\n",
    "        plt.savefig(__OUTPUT + f'Congested_Links_Visualized_SRC-{i * 10}%_Rho-{rho}.png', transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8de27-38d5-4bda-b5c6-26785646d649",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need the gdf from the above section\n",
    "congested_gdf = copy.deepcopy(gdf)\n",
    "congested = copy.deepcopy(congested_gdf)\n",
    "sections_congested = []\n",
    "\n",
    "# Filter out the congested sections\n",
    "for i in range(__NUM_EXP):\n",
    "    congested[i] = congested[i][congested[i]['congested at rho = {number}'.format(number=0.7)] == 1]\n",
    "    congested[i] = congested[i][['ent', 'eid', 'congested at rho = {number}'.format(number=0.7)]]\n",
    "\n",
    "# Map the congested sections to the sections.shp\n",
    "for i in range(__NUM_EXP):\n",
    "    sections_congested.append(sections[sections['eid'].isin(congested[i]['eid'])])\n",
    "\n",
    "for threshold in rho:\n",
    "    plot_congested_links(congested_gdf, sections, round(threshold, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f6127",
   "metadata": {},
   "source": [
    "## Percentage of Congested Links by Road Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1683a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a095663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the sections with missing average speed\n",
    "df_total = []\n",
    "df_local = []\n",
    "df_throu = []\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] >= 0.0]\n",
    "    df_total.append(copy.deepcopy(df[i][df[i]['sid'] == 0]))\n",
    "    df_local.append(copy.deepcopy(df[i][df[i]['sid'] == 1]))\n",
    "    df_throu.append(copy.deepcopy(df[i][df[i]['sid'] == 2]))\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_throu[i].shape for i in range(__NUM_EXP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe9af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_length = sections['geometry'].length.sum()\n",
    "total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1a645-9a1f-4e7f-962f-e7fc30504da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_num_sections = len(sections['eid'].unique())\n",
    "total_num_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c133284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections_by_road_type = []\n",
    "for i in range(5):\n",
    "    sections_by_road_type.append(sections[sections['func_class'] == i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c5b58-c41a-404c-b9c5-c252c465e488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_congested_gdf_agg(sections_gdf):\n",
    "    # Convert the merged sections into GeoDataFrame and drop null values\n",
    "    gdf = []\n",
    "    for i in range(__NUM_EXP):\n",
    "        gdf.append(gpd.GeoDataFrame(sections_gdf[i], geometry='geometry'))\n",
    "        gdf[i]['speed'] = gdf[i]['speed'].dropna()\n",
    "        gdf[i]['length'] = gdf[i]['geometry'].length\n",
    "\n",
    "    # Add a column for each section at each threshold,\n",
    "    # congested = 1, else 0\n",
    "    for threshold in rho:\n",
    "        for i in range(__NUM_EXP):\n",
    "            speed_ratio = gdf[i]['speed'] / gdf[i]['speed_limit']\n",
    "            gdf[i]['congested at rho = ' + str(round(threshold, 1))] = list(np.array([int(r < threshold) for r in speed_ratio]) / total_num_sections)\n",
    "\n",
    "    # Add a column for congestion weight at each threshold,\n",
    "    # congested = 1, else 0\n",
    "    for threshold in rho:\n",
    "        for i in range(__NUM_EXP):\n",
    "            weight = gdf[i]['length'] * gdf[i]['congested at rho = ' + str(round(threshold, 1))] * total_num_sections\n",
    "            gdf[i]['weight at rho = ' + str(round(threshold, 1))] = weight\n",
    "\n",
    "    # Group each GeoDataFrame on timestep and aggregate by sum\n",
    "    # Remove the first row as it is the average of the rest\n",
    "    gdf_agg = []\n",
    "    for i in range(__NUM_EXP):\n",
    "        gdf_agg.append(gdf[i].groupby('ent').agg(np.sum).iloc[1:, :])\n",
    "\n",
    "    for threshold in rho:\n",
    "        for i in range(__NUM_EXP):\n",
    "            gdf_agg[i]['congestion ratio at rho = ' + str(round(threshold, 1))] = gdf_agg[i]['weight at rho = ' + str(round(threshold, 1))] / total_length\n",
    "            \n",
    "    return copy.deepcopy(gdf_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2accf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess dataframe to merge with sections\n",
    "\n",
    "group_cols = ['ent', 'eid']\n",
    "# identify the columns which we want to average; this could\n",
    "# equivalently be defined as list(df.columns[4:])\n",
    "metric_cols = ['speed']\n",
    "\n",
    "# create a new DataFrame with a MultiIndex consisting of the group_cols\n",
    "# and a column for the mean of each column in metric_cols\n",
    "aggs = []\n",
    "for i in range(__NUM_EXP):\n",
    "    aggs.append(df_total[i].groupby(group_cols)[metric_cols].mean())\n",
    "\n",
    "# 1. remove the metric_cols from df because we are going to replace them\n",
    "# with the means in aggs \n",
    "# 2. dedupe to leave only one row with each combination of group_cols\n",
    "# in df\n",
    "for i in range(__NUM_EXP):\n",
    "    # Step 1\n",
    "    df_total[i].drop(metric_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Step 2\n",
    "    # df[i].drop_duplicates(subset=group_cols, keep='last', inplace=True) # No dedupe for congestion\n",
    "\n",
    "# add the mean columns from aggs into df\n",
    "for i in range(__NUM_EXP):\n",
    "    df_total[i] = df_total[i].merge(right=aggs[i], right_index=True, left_on=group_cols, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e29c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_congestion_percentage_by_road_type(road_type, isWeighted=True, savefig=True):\n",
    "    # Merge datasets: sections and dataframe\n",
    "    sections_cong = []\n",
    "    sections_by_type = []\n",
    "\n",
    "    if isinstance(road_type, list):\n",
    "        sections_by_type = sections[sections['func_class'].isin(road_type)]\n",
    "    elif isinstance(road_type, int):\n",
    "        sections_by_type = sections[sections['func_class'] == road_type]\n",
    "    else:\n",
    "        raise Exception(\"Invalid road type (function class)!\")\n",
    "    \n",
    "    for i in range(__NUM_EXP):\n",
    "        sections_cong.append(pd.merge(df_total[i], sections_by_type, how='left', left_on='eid', right_on='eid'))\n",
    "        \n",
    "    gdf_agg = get_congested_gdf_agg(sections_cong)\n",
    "        \n",
    "    # Plot the aggregated(mean) flow-capacity ratio at each timestep for each experiment\n",
    "    for threshold in rho:\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        if isWeighted:\n",
    "            plot_experiment(gdf_agg, 'congestion ratio at rho = ' + str(round(threshold, 1)))\n",
    "            title = 'Weighted Congestion Ratio over Time Step (Threshold = {threshold}) for Road Type {rt}'.format(threshold=str(round(threshold, 1)), rt=road_type)\n",
    "        else:\n",
    "            plot_experiment(gdf_agg, 'congested at rho = ' + str(round(threshold, 1)))\n",
    "            title = 'Unweighted Congestion Ratio over Time Step (Threshold = {threshold}) for Road Type {rt}'.format(threshold=str(round(threshold, 1)), rt=road_type)\n",
    "\n",
    "        plt.legend([\"0% SRC(All SUE)\",\n",
    "                             \"10% SRC\",\n",
    "                             \"20% SRC\",\n",
    "                             \"30% SRC\",\n",
    "                             \"40% SRC\",\n",
    "                             \"50% SRC\",\n",
    "                             \"60% SRC\",\n",
    "                             \"70% SRC\",\n",
    "                             \"80% SRC\",\n",
    "                             \"90% SRC\",\n",
    "                             \"100% All SRC (No SUE)\"])\n",
    "        \n",
    "        plt.title(title)\n",
    "        default_x_ticks = range(len(__TIME_REAL))\n",
    "        plt.xticks(default_x_ticks, __TIME_REAL, fontsize='15', rotation=45)\n",
    "        plt.yticks(fontsize='15')\n",
    "        if savefig:\n",
    "            plt.savefig(__OUTPUT + f'{title}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdeb2b",
   "metadata": {},
   "source": [
    "### Road Type Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60afa9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8ca30",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f633561",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcb7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df4b2f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7c3dd-af2a-4edb-95b6-475676a8c63f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf022ca3-3a78-4aad-bce4-2e2b79e1d4aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type([1, 2, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a06a6e-9950-455d-a2a9-ebb31b9ccacd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(1, isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28072189-7936-409d-ae6f-8333521ea287",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(2, isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8a1ff-9d60-4a08-b67d-3dbce601d241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(3, isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bec39-593a-4c7e-8507-3299623105d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type(5, isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b51fb3-ad20-4229-97fc-7dfcff8461d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type([1, 2, 3], isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090704d-1b66-4de2-9d1b-9c5b7281c588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_congestion_percentage_by_road_type([1, 2, 3, 5], isWeighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be9047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_roads_by_type(func_class, savefig=True):\n",
    "    if isinstance(func_class, int):\n",
    "        func_class = [func_class]\n",
    "    ax = sections[sections['func_class'].isin(func_class)].plot(figsize=(15, 15))\n",
    "    # cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "    title = f'Road Sections of Type {func_class}'\n",
    "    plt.xlim([591900, 597200])\n",
    "    plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        plt.savefig(__OUTPUT + f'{title}.png', transparent=True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f1578",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00e928",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363afe3-14ad-40f9-b469-c6e5a30d7d6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e09c74-63b7-4e20-a87f-26a45e63dc5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68541edb-c410-4066-8cc3-024d648dcda4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bc671",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roads_by_type([5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7e0e9",
   "metadata": {},
   "source": [
    "## Plotting for different timesteps for an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d19ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_congestion_experiment(gdf, sections, rho):\n",
    "    congested = copy.deepcopy(gdf)\n",
    "    sections = copy.deepcopy(sections)\n",
    "    sections_congested = []\n",
    "    \n",
    "    # Filter out the congested sections\n",
    "    for i in range(__NUM_EXP):\n",
    "        congested[i] = congested[i][congested[i]['congested at rho = {number}'.format(number=rho)] == 1]\n",
    "        congested[i] = congested[i][['ent', 'eid', 'congested at rho = {number}'.format(number=rho)]]\n",
    "        \n",
    "    # Map the congested sections to the sections.shp\n",
    "    for i in range(__NUM_EXP):\n",
    "        sections_congested.append(sections[sections['eid'].isin(congested[i]['eid'])])\n",
    "        \n",
    "    # Plot\n",
    "    for i in range(__NUM_EXP): # Experiment with smaller range\n",
    "        ax = sections_congested[i].plot(figsize=(15, 15), color='red')\n",
    "        # cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) # removing does not make the map same scale\n",
    "        plt.xlim([591900, 597200])\n",
    "        plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "        plt.title('Congestion Points when Threshold = {number} where SRC = {percent}%'.format(number=rho, percent=i*10))\n",
    "        plt.savefig(__OUTPUT + f'Congestion_Visualized_SRC-{i * 10}%_Rho-{rho}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897b5cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need the gdf from the above section\n",
    "congested_gdf = copy.deepcopy(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5fb51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for threshold in rho:\n",
    "    plot_congestion_experiment(congested_gdf, sections, round(threshold, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eeaa6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_congestion_experiment_step(gdf, sections, rho, ent, savefig=True):\n",
    "    congested = copy.deepcopy(gdf)\n",
    "    sections = copy.deepcopy(sections)\n",
    "    sections_congested = []\n",
    "    \n",
    "    # Filter out the congested sections\n",
    "    for i in range(__NUM_EXP):\n",
    "        congested[i] = congested[i][(congested[i]['congested at rho = {number}'.format(number=rho)] == 1) & (congested[i]['ent'] == ent)]\n",
    "        congested[i] = congested[i][['ent', 'eid', 'congested at rho = {number}'.format(number=rho)]]\n",
    "        \n",
    "    # Map the congested sections to the sections.shp\n",
    "    for i in range(__NUM_EXP):\n",
    "        sections_congested.append(sections[sections['eid'].isin(congested[i]['eid'])])\n",
    "        \n",
    "    # Plot\n",
    "    for i in range(__NUM_EXP): # Experiment with smaller range\n",
    "        ax = sections_congested[i].plot(figsize=(15, 15), color='red')\n",
    "        # cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) # removing does not make the map same scale\n",
    "        plt.xlim([591900, 597200])\n",
    "        plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "        # plt.xticks(fontsize=24, rotation=45)\n",
    "        # plt.yticks(fontsize=24)\n",
    "        scale_bar = ScaleBar(\n",
    "            dx=1,\n",
    "            location='upper left',  # in relation to the whole plot\n",
    "            label_loc='left', scale_loc='bottom'  # in relation to the line\n",
    "        )\n",
    "        ax.add_artist(scale_bar)\n",
    "        x, y, arrow_length = 0.05, 0.95, 0.07\n",
    "        ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "                    arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "                    ha='center', va='center', fontsize=20,\n",
    "                    xycoords=ax.transAxes)\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "        ax.yaxis.set_tick_params(labelleft=False)\n",
    "        title = 'Congestion Points when Threshold = {number} where SRC = {percent}% at {time}'.format(number=rho, percent=i*10, time=__TIME_REAL[ent])\n",
    "        # plt.title(title)\n",
    "        \n",
    "        if savefig:\n",
    "            plt.savefig(__OUTPUT + f'{title}.png', transparent=True)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd3efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need the gdf from the above section\n",
    "congested_gdf = copy.deepcopy(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e049d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ent in range(24):\n",
    "    for threshold in rho:\n",
    "        plot_congestion_experiment_step(congested_gdf, sections, round(threshold, 1), ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf0080",
   "metadata": {},
   "source": [
    "## Comparing Vehicle Kilometers Traveled (VKT) and Delay Time under Different SRC User Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a50339-f884-497f-88c9-4e6ea6980e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020832d-3253-40cf-a14e-45d9360e4b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the sections with missing average speed\n",
    "df_total = []\n",
    "df_local = []\n",
    "df_throu = []\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] >= 0.0]\n",
    "    df_total.append(copy.deepcopy(df[i][df[i]['sid'] == 0]))\n",
    "    df_local.append(copy.deepcopy(df[i][df[i]['sid'] == 1]))\n",
    "    df_throu.append(copy.deepcopy(df[i][df[i]['sid'] == 2]))\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_throu[i].shape for i in range(__NUM_EXP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18f1b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vkt_df_total = copy.deepcopy(df_total)\n",
    "vkt_df_local = copy.deepcopy(df_local)\n",
    "vkt_df_throu = copy.deepcopy(df_throu)\n",
    "for i in range(__NUM_EXP):\n",
    "    vkt_df_total[i] = vkt_df_total[i].groupby('eid').agg(np.sum)\n",
    "    vkt_df_local[i] = vkt_df_local[i].groupby('eid').agg(np.sum)\n",
    "    vkt_df_throu[i] = vkt_df_throu[i].groupby('eid').agg(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad28ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vkt_total = []\n",
    "vkt_local = []\n",
    "vkt_throu = []\n",
    "delay_total = []\n",
    "delay_local = []\n",
    "delay_throu = []\n",
    "ttime_total = []\n",
    "ttime_local = []\n",
    "ttime_throu = []\n",
    "for i in range(__NUM_EXP):\n",
    "    vkt_total.append(np.sum(vkt_df_total[i]['travel']))\n",
    "    vkt_local.append(np.sum(vkt_df_local[i]['travel']))\n",
    "    vkt_throu.append(np.sum(vkt_df_throu[i]['travel']))\n",
    "    delay_total.append(np.mean(vkt_df_total[i]['dtime']))\n",
    "    delay_local.append(np.mean(vkt_df_local[i]['dtime']))\n",
    "    delay_throu.append(np.mean(vkt_df_throu[i]['dtime']))\n",
    "    ttime_total.append(np.mean(vkt_df_total[i]['traveltime']))\n",
    "    ttime_local.append(np.mean(vkt_df_local[i]['traveltime']))\n",
    "    ttime_throu.append(np.mean(vkt_df_throu[i]['traveltime']))\n",
    "print(vkt_total)\n",
    "print(vkt_local)\n",
    "print(vkt_throu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6329aa-65af-4697-b2d4-62637fe2fbe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_vkt(vkt, vkt_type='Total', savefig=True):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    x = range(11)\n",
    "    y = vkt\n",
    "    labels = [\"0% SRC(All SUE)\",\n",
    "                         \"10% SRC\",\n",
    "                         \"20% SRC\",\n",
    "                         \"30% SRC\",\n",
    "                         \"40% SRC\",\n",
    "                         \"50% SRC\",\n",
    "                         \"60% SRC\",\n",
    "                         \"70% SRC\",\n",
    "                         \"80% SRC\",\n",
    "                         \"90% SRC\",\n",
    "                         \"100% All SRC (No SUE)\"]\n",
    "    plt.plot(x, y)\n",
    "    plt.ylabel('Kilometers')\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.margins(0.2)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    title = f'{vkt_type} VKT Under Different SRC'\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        plt.savefig(__OUTPUT + f'{title}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37bf5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_vkt(vkt_total, 'Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed4cdf-60f0-4ef2-bb0d-f5c68ee11f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_vkt(vkt_local, 'Resident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d6b5c-9038-46fd-bb41-728e23b5c250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_vkt(vkt_throu, 'Traveler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c83cf-448e-4b29-a427-df0b7acbc421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_delay(delay, delay_type='Total', savefig=True):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    x = range(11)\n",
    "    y = delay\n",
    "    labels = [\"0% SRC(All SUE)\",\n",
    "                         \"10% SRC\",\n",
    "                         \"20% SRC\",\n",
    "                         \"30% SRC\",\n",
    "                         \"40% SRC\",\n",
    "                         \"50% SRC\",\n",
    "                         \"60% SRC\",\n",
    "                         \"70% SRC\",\n",
    "                         \"80% SRC\",\n",
    "                         \"90% SRC\",\n",
    "                         \"100% All SRC (No SUE)\"]\n",
    "    plt.plot(x, y)\n",
    "    plt.ylabel('seconds/vehicle')\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.ylim([0, 150])\n",
    "    plt.margins(0.2)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    title = f'{delay_type} Mean Delay Under Different SRC'\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        plt.savefig(__OUTPUT + f'{title}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83250a-bd4c-4833-b208-5929311c989e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_delay(delay_total, 'Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef68cb-d108-4214-bced-ead669dc777a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_delay(delay_local, 'Resident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7717ee1-e9a6-485a-92dc-699f8ba46f59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_delay(delay_throu, 'Traveler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4782d-1836-4876-b7d9-bd041aa266fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_travel_time(ttime, delay_type='Total', savefig=True):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    x = range(11)\n",
    "    y = ttime\n",
    "    labels = [\"0% SRC(All SUE)\",\n",
    "                         \"10% SRC\",\n",
    "                         \"20% SRC\",\n",
    "                         \"30% SRC\",\n",
    "                         \"40% SRC\",\n",
    "                         \"50% SRC\",\n",
    "                         \"60% SRC\",\n",
    "                         \"70% SRC\",\n",
    "                         \"80% SRC\",\n",
    "                         \"90% SRC\",\n",
    "                         \"100% All SRC (No SUE)\"]\n",
    "    # plt.yscale(\"log\") \n",
    "    plt.plot(x, y)\n",
    "    plt.ylabel('seconds/vehicle')\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    # plt.ylim([5000, 40000])\n",
    "    plt.margins(0.2)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    title = f'{delay_type} Mean Travel Time Under Different SRC'\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        plt.savefig(__OUTPUT + f'{title}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1272331-acf3-4a53-a7ad-9c6fdbb42bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_travel_time(ttime_total, 'Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd5868-87b0-489c-a282-ebfced3399c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_travel_time(ttime_local, 'Resident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c86dbc-9665-4059-b30a-beee269fb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_travel_time(ttime_throu, 'Traveler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a65e6",
   "metadata": {},
   "source": [
    "# Visualize the Congested Area on the Map at Different SRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9336aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need the gdf from the above section\n",
    "congested_gdf = copy.deepcopy(gdf)\n",
    "congested_gdf[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77db56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_congestion_experiment(gdf, sections, rho):\n",
    "    congested = copy.deepcopy(gdf)\n",
    "    sections = copy.deepcopy(sections)\n",
    "    sections_congested = []\n",
    "    \n",
    "    # Filter out the congested sections\n",
    "    for i in range(__NUM_EXP):\n",
    "        congested[i] = congested[i][congested[i]['congested at rho = {number}'.format(number=rho)] == 1]\n",
    "        congested[i] = congested[i][['ent', 'eid', 'congested at rho = {number}'.format(number=rho)]]\n",
    "        \n",
    "    # Map the congested sections to the sections.shp\n",
    "    for i in range(__NUM_EXP):\n",
    "        sections_congested.append(sections[sections['eid'].isin(congested[i]['eid'])])\n",
    "        \n",
    "    # Plot\n",
    "    for i in range(__NUM_EXP): # Experiment with smaller range\n",
    "        ax = sections_congested[i].plot(figsize=(15, 15))\n",
    "        print(sections_congested[i].crs)\n",
    "        # cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "#         plt.xlim([591900, 597200])\n",
    "#         plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "        plt.title('Congestion Points when rho = {number} where SRC = {percent}%'.format(number=rho, percent=i*10))\n",
    "        # plt.savefig(__OUTPUT + f'Congestion_Visualized_SRC-{i * 10}%_Rho-{rho}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37f6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for threshold in rho:\n",
    "    plot_congestion_experiment(congested_gdf, sections, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3d3c6-5d4f-4bca-9066-c748983e00e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Macroscopic Fundamental Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10a66c-ebcd-439c-97b5-1b31df0a236b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)\n",
    "df_milane = copy.deepcopy(df_milane_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002e259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the sections with missing average speed\n",
    "df_total = []\n",
    "df_local = []\n",
    "df_throu = []\n",
    "df_milane_total = []\n",
    "df_milane_local = []\n",
    "df_milane_throu = []\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] >= 0.0]\n",
    "    df_milane[i] = df_milane[i][(df_milane[i]['speed'] >= 0.0) & (df_milane[i]['density'] >= 0.5)]\n",
    "    df_total.append(copy.deepcopy(df[i][df[i]['sid'] == 0]))\n",
    "    df_local.append(copy.deepcopy(df[i][df[i]['sid'] == 1]))\n",
    "    df_throu.append(copy.deepcopy(df[i][df[i]['sid'] == 2]))\n",
    "    df_milane_total.append(copy.deepcopy(df_milane[i][df_milane[i]['sid'] == 0]))\n",
    "    df_milane_local.append(copy.deepcopy(df_milane[i][df_milane[i]['sid'] == 1]))\n",
    "    df_milane_throu.append(copy.deepcopy(df_milane[i][df_milane[i]['sid'] == 2]))\n",
    "print([df[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_throu[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_milane[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_milane_total[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_milane_local[i].shape for i in range(__NUM_EXP)])\n",
    "print([df_milane_throu[i].shape for i in range(__NUM_EXP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4aa48-d866-4aaf-bb3c-47fe7179cb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_MFD(avg=False, savefig=True):\n",
    "    for i in range(__NUM_EXP):\n",
    "        x_dens = df_milane_total[i]['density'].tolist()\n",
    "        y_flow = df_milane_total[i]['input_flow'].tolist()\n",
    "        xp = np.linspace(0, max(x_dens), 1000)\n",
    "        poly = np.poly1d(np.polyfit(x_dens, y_flow, 3))\n",
    "        plt.scatter(x_dens, y_flow, alpha=0.2)\n",
    "        plt.plot(xp, poly(xp), '-', color='orange')\n",
    "        # plt.xlim(0, 50)\n",
    "        plt.ylim(bottom=0)\n",
    "        if avg:\n",
    "            plt.xlabel('avg density (veh/km per lane)')\n",
    "            plt.ylabel('avg flow (veh/h per lane)')\n",
    "            plt.xlim([0, 100])\n",
    "            title = f'Avg MFD for Experiment {i}'\n",
    "        else: \n",
    "            plt.xlabel('density (veh/km per lane)')\n",
    "            plt.ylabel('flow (veh/h per lane)')\n",
    "            title = f'MFD for Experiment {i}'\n",
    "        plt.title(title)\n",
    "        if savefig:\n",
    "            plt.savefig(__OUTPUT + f'{title}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb3f02-510a-4841-a0d0-a2f6cae1c093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_MFD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c86918-183c-4749-8c97-befbac44be39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggs_milane = []\n",
    "for i in range(__NUM_EXP):\n",
    "    df_milane_total[i] = df_milane_total[i][df_milane_total[i]['flow'] > 0.0]\n",
    "\n",
    "group_cols = ['eid']\n",
    "# identify the columns which we want to average\n",
    "metric_cols = ['density', 'input_flow', 'flow']\n",
    "\n",
    "# create a new DataFrame with a MultiIndex consisting of the group_cols\n",
    "# and a column for the mean of each column in metric_cols\n",
    "for i in range(__NUM_EXP):\n",
    "    aggs_milane.append(df_milane_total[i].groupby(group_cols)[metric_cols].mean())\n",
    "\n",
    "# 1. remove the metric_cols from df because we are going to replace them\n",
    "# with the means in aggs \n",
    "# 2. dedupe to leave only one row with each combination of group_cols\n",
    "# in df\n",
    "for i in range(__NUM_EXP):\n",
    "    # Step 1\n",
    "    df_milane_total[i].drop(metric_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Step 2\n",
    "    df_milane_total[i].drop_duplicates(subset=group_cols, keep='last', inplace=True) # dedupe for plotting aggregated data\n",
    "\n",
    "# add the mean columns from aggs into df\n",
    "for i in range(__NUM_EXP):\n",
    "    df_milane_total[i] = df_milane_total[i].merge(right=aggs_milane[i], right_index=True, left_on=group_cols, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e33da-8b44-4ce1-9f90-590724afb20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_MFD(avg=True) # w/ dedupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d5787-3f9f-4f96-91f4-47391aa4f570",
   "metadata": {},
   "source": [
    "# Generate Base Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b78b4-414f-49a3-ad6e-eaf7738396b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections = copy.deepcopy(sections_copy)\n",
    "ax = sections.plot(figsize=(15, 15), color='None')\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.xlim([591900, 597200])\n",
    "plt.ylim([4.148 * 1e6, 4.158 * 1e6])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(__OUTPUT + 'basemap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe90f6-a292-4afd-bba5-40446e01a430",
   "metadata": {},
   "source": [
    "# Draw Sections without Recorded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b72213-3ddd-4530-a78f-dc7b28032c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the sections file in case of modification\n",
    "sections = copy.deepcopy(sections_copy)\n",
    "sections = sections.rename(columns={'speed': 'speed_limit'})\n",
    "df = copy.deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18a0d0-b3fc-43fc-b372-2a36d2f2973a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(__NUM_EXP):\n",
    "    df[i] = df[i][df[i]['speed'] < 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da034db-b04a-4dbc-991d-50ce76d6ab97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge datasets: sections and dataframe\n",
    "sections_null = []\n",
    "\n",
    "for i in range(__NUM_EXP):\n",
    "    sections_null.append(pd.merge(df[i], sections, how='left', left_on='eid', right_on='eid'))\n",
    "    \n",
    "# # convert to GeoDataframe\n",
    "# gdf_null = gpd.GeoDataFrame(sections_null, geometry='geometry')\n",
    "# gdf_null.head()\n",
    "\n",
    "ax = sections_null[0].plot(figsize=(15, 15))\n",
    "cx.add_basemap(ax, crs='EPSG:32610', source=cx.providers.CartoDB.Voyager) #4326\n",
    "plt.title('Road Sections')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fremont",
   "language": "python",
   "name": "fremont"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
